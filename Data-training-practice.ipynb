{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144dc564",
   "metadata": {},
   "source": [
    "##  Model Training \n",
    "\n",
    "This code is to understand `engine.py`.\n",
    "\n",
    "This code is to load `PTVflow3D` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb743d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#from datasets.generic import Batch\n",
    "from model.RAFTSceneFlow import RSF_DGCNN\n",
    "from tools.loss import sequence_loss\n",
    "\n",
    "from tools.metric import compute_epe_train, compute_epe2, compute_rmse_train, compute_rmse\n",
    "from tools.utils import save_checkpoint\n",
    "from deepptv.data import FluidflowDataset, FluidflowDataset3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f84f6",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640d7469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  1\n",
      "test :  10\n"
     ]
    }
   ],
   "source": [
    "num_points = 512\n",
    "folder = 'PTVflow3D_norm' # 'data_sample'\n",
    "dataset_path = os.path.join('data/training_set', folder)\n",
    "train_dataset = FluidflowDataset3D(npoints=num_points, root = dataset_path, partition='train')\n",
    "val_dataset = FluidflowDataset3D(npoints=num_points, root = dataset_path, partition='test')\n",
    "test_dataset = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3afcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "test_batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True,\n",
    "                                           num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, test_batch_size, shuffle=False, num_workers=4,\n",
    "                                         drop_last=False)\n",
    "test_dataloader = val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade70958",
   "metadata": {},
   "source": [
    "## 2. Load the model\n",
    "\n",
    "The model is `RSF_DGCNN model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1401ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model.extractor import FlotEncoder, FlotGraph\n",
    "from model.corr2 import CorrBlock2\n",
    "from model.update import UpdateBlock\n",
    "from model.scale import KnnDistance\n",
    "import model.ot as ot\n",
    "from model.model_dgcnn import GeoDGCNN_flow2\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model.flot.gconv import GeoSetConv\n",
    "from model.flot.graph import ParGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972024d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e246896",
   "metadata": {},
   "source": [
    "## 2.1 Feature Extration Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae554df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from `model_dgcnn.py`\n",
    "def knn(x, k):\n",
    "    # return the index of k-nearest data of x\n",
    "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
    "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
    "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
    " \n",
    "    idx = pairwise_distance.topk(k=k, dim=-1)[1]   \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f5ac3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size,num_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f58680",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# 0,512,1024\n",
    "idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b594142",
   "metadata": {},
   "source": [
    "## 2.2 CorrBlock 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a774785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32d7611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrBlock2(nn.Module):\n",
    "    def __init__(self, num_levels=3, base_scale=0.25, resolution=3, truncate_k=128, knn=32):\n",
    "        super(CorrBlock2, self).__init__()\n",
    "        self.truncate_k = truncate_k\n",
    "        self.num_levels = num_levels\n",
    "        self.resolution = resolution  # local resolution\n",
    "        self.base_scale = base_scale  # search (base_sclae * resolution)^3 cube\n",
    "        self.out_conv = nn.Sequential(\n",
    "            nn.Conv1d((self.resolution ** 3) * self.num_levels, 128, 1),\n",
    "            nn.GroupNorm(8, 128),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv1d(128, 64, 1)\n",
    "        )\n",
    "        self.knn = knn # 32\n",
    "        \n",
    "        self.knn_conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 64, 1),\n",
    "            nn.GroupNorm(8, 64),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.knn_out = nn.Conv1d(64, 64, 1)\n",
    "    def init_module(self, fmap1, fmap2, xyz2, transport):\n",
    "        b, n_p, _ = xyz2.size()\n",
    "        xyz2 = xyz2.view(b, 1, n_p, 3).expand(b, n_p, n_p, 3)\n",
    "        # corr = self.calculate_corr(fmap1, fmap2)\n",
    "        # corr = self.calculate_ncc(fmap1, fmap2)  \n",
    "        corr = transport  \n",
    "        corr_topk = torch.topk(corr.clone(), k=self.truncate_k, dim=2, sorted=True)\n",
    "        self.truncated_corr = corr_topk.values\n",
    "        indx = corr_topk.indices.reshape(b, n_p, self.truncate_k, 1).expand(b, n_p, self.truncate_k, 3)\n",
    "        self.ones_matrix = torch.ones_like(self.truncated_corr)\n",
    "        \n",
    "        self.truncate_xyz2 = torch.gather(xyz2, dim=2, index=indx)  # b, n_p1, k, 3\n",
    "\n",
    "    def __call__(self, coords, all_delta_flow, num_iters, scale):\n",
    "        \n",
    "        return self.get_adaptive_voxel_feature2(coords, all_delta_flow, num_iters, scale) + self.get_dynamic_knn_feature(coords, all_delta_flow)  ######## modified ########\n",
    "    \n",
    "    def get_adaptive_voxel_feature2(self, coords, all_delta_flow, num_iters, scale):\n",
    "        b, n_p, _ = coords.size()\n",
    "        corr_feature = []\n",
    "        from torch_scatter import scatter_add\n",
    "        for i in range(self.num_levels):\n",
    "            r = scale * (2 ** i)\n",
    "            dis_voxel = torch.round((self.truncate_xyz2 - coords.unsqueeze(dim=-2)) / r) # [B, N, truncate_k, 3]\n",
    "            ### TO DO ###\n",
    "            ids = len(all_delta_flow)\n",
    "            if ids >= 2 and ids < (num_iters-2):\n",
    "                r1_norm = torch.norm(all_delta_flow[-1], dim=-1, keepdim=True)  # [B, N, 1]\n",
    "                r1_max = torch.max(r1_norm, dim=1, keepdim=True)[0] # [B, 1, 1]\n",
    "                cos1 = torch.cosine_similarity(all_delta_flow[-1], all_delta_flow[-2], dim=-1).unsqueeze(dim=-1)  # [B, N, 1]\n",
    "                r1_len = all_delta_flow[-1] / r1_norm * (0.125*r1_norm/r1_max + 0.125*cos1 + 1) * r # self.base_scale\n",
    "                r1 = r1_len.unsqueeze(dim=-2).repeat(1, 1, self.truncate_xyz2.shape[2], 1) # [B, N, truncate_k, 3]\n",
    "                r2_p = all_delta_flow[-2] - cos1 * torch.norm(all_delta_flow[-2], dim=-1, keepdim=True) * all_delta_flow[-1] / r1_norm\n",
    "                r2_norm = torch.norm(r2_p, dim=-1, keepdim=True)  # [B, N, 1]\n",
    "                r2_max = torch.max(r2_norm, dim=1, keepdim=True)[0] # [B, 1, 1]\n",
    "                r2_len = r2_p / r2_norm * (0.125*r2_norm/r2_max + 0.9) * r # self.base_scale\n",
    "                r2 = r2_len.unsqueeze(dim=-2).repeat(1, 1, self.truncate_xyz2.shape[2], 1)\n",
    "                r3_cross = torch.cross(all_delta_flow[-1], all_delta_flow[-2])\n",
    "                r3_len = r3_cross / torch.norm(r3_cross, dim=-1, keepdim=True) * 0.9 * r # self.base_scale\n",
    "                r3 = r3_len.unsqueeze(dim=-2).repeat(1, 1, self.truncate_xyz2.shape[2], 1)\n",
    "                dis_voxel[:, :, :, 0] = torch.round(torch.sum((self.truncate_xyz2 - coords.unsqueeze(dim=-2)) * r1, dim=-1) / torch.norm(r1, dim=-1))\n",
    "                dis_voxel[:, :, :, 1] = torch.round(torch.sum((self.truncate_xyz2 - coords.unsqueeze(dim=-2)) * r2, dim=-1) / torch.norm(r2, dim=-1))\n",
    "                dis_voxel[:, :, :, 2] = torch.round(torch.sum((self.truncate_xyz2 - coords.unsqueeze(dim=-2)) * r3, dim=-1) / torch.norm(r3, dim=-1))\n",
    "            ### TO DO ###\n",
    "            valid_scatter = (torch.abs(dis_voxel) <= np.floor(self.resolution / 2)).all(dim=-1) # [B, N, truncate_k]\n",
    "            dis_voxel = dis_voxel - (-1)\n",
    "            cube_idx = dis_voxel[:, :, :, 0] * (self.resolution ** 2) +\\\n",
    "                dis_voxel[:, :, :, 1] * self.resolution + dis_voxel[:, :, :, 2] # [B, N, truncate_k]\n",
    "            cube_idx_scatter = cube_idx.type(torch.int64) * valid_scatter\n",
    "\n",
    "            valid_scatter = valid_scatter.detach()\n",
    "            cube_idx_scatter = cube_idx_scatter.detach()\n",
    "\n",
    "            corr_add = scatter_add(self.truncated_corr * valid_scatter, cube_idx_scatter)\n",
    "            corr_cnt = torch.clamp(scatter_add(self.ones_matrix * valid_scatter, cube_idx_scatter), 1, n_p)\n",
    "            corr = corr_add / corr_cnt\n",
    "            if corr.shape[-1] != self.resolution ** 3:\n",
    "                repair = torch.zeros([b, n_p, self.resolution ** 3 - corr.shape[-1]], device=coords.device)\n",
    "                corr = torch.cat([corr, repair], dim=-1)\n",
    "\n",
    "            corr_feature.append(corr.transpose(1, 2).contiguous())\n",
    "\n",
    "        return self.out_conv(torch.cat(corr_feature, dim=1))\n",
    "\n",
    "    ######## modified ########\n",
    "    def get_dynamic_knn_feature(self, coords, all_delta_flow):\n",
    "        b, n_p, _ = coords.size()\n",
    "\n",
    "        dist = self.truncate_xyz2 - coords.view(b, n_p, 1, 3)\n",
    "        dist = torch.sum(dist ** 2, dim=-1)     # b, 8192, 512\n",
    "\n",
    "        if len(all_delta_flow) < 8: ## *modified 20220401* ##\n",
    "            dynamic_k = self.knn - 2 * len(all_delta_flow)\n",
    "        else:\n",
    "            dynamic_k = self.knn - 2 * 8\n",
    "        # dynamic_k = self.knn - 2 * len(all_delta_flow)\n",
    "        neighbors = torch.topk(-dist, k=dynamic_k, dim=2).indices\n",
    "\n",
    "        b, n_p, _ = coords.size()\n",
    "        knn_corr = torch.gather(self.truncated_corr.view(b * n_p, self.truncate_k), dim=1,\n",
    "                                index=neighbors.reshape(b * n_p, dynamic_k)).reshape(b, 1, n_p, dynamic_k)\n",
    "\n",
    "        neighbors = neighbors.view(b, n_p, dynamic_k, 1).expand(b, n_p, dynamic_k, 3)\n",
    "        knn_xyz = torch.gather(self.truncate_xyz2, dim=2, index=neighbors).permute(0, 3, 1, 2).contiguous()\n",
    "        knn_xyz = knn_xyz - coords.transpose(1, 2).reshape(b, 3, n_p, 1)\n",
    "\n",
    "        knn_feature = self.knn_conv(torch.cat([knn_corr, knn_xyz], dim=1)) # [B, C, N, K]\n",
    "        knn_feature = torch.max(knn_feature, dim=3)[0] # [B, C, N]\n",
    "        return self.knn_out(knn_feature)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_corr(fmap1, fmap2):\n",
    "        batch, dim, num_points = fmap1.shape\n",
    "        corr = torch.matmul(fmap1.transpose(1, 2), fmap2)\n",
    "        corr = corr / torch.sqrt(torch.tensor(dim).float())\n",
    "        return corr\n",
    "\n",
    "    ###### *modified* ######\n",
    "    @staticmethod\n",
    "    def calculate_ncc(fmap1, fmap2):\n",
    "        batch, dim, num_points = fmap1.shape\n",
    "        corr = torch.matmul(fmap1.transpose(1, 2), fmap2)\n",
    "        # corr = corr / torch.sqrt(torch.tensor(dim).float())\n",
    "        n1 = torch.norm(fmap1, dim=1, keepdim=True)\n",
    "        n2 = torch.norm(fmap2, dim=1, keepdim=True)\n",
    "        ncc = corr / torch.matmul(n1.transpose(1, 2), n2)\n",
    "        return ncc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4662b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from `model_dgcnn.py`\n",
    "def get_graph_feature(x, k=20, idx=None, dim9=False):\n",
    "    batch_size = x.size(0)\n",
    "    num_points = x.size(2)\n",
    "    x = x.view(batch_size, -1, num_points)\n",
    "    if idx is None:\n",
    "        if dim9 == False:\n",
    "            idx = knn(x, k=k)   \n",
    "        else:\n",
    "            idx = knn(x[:, 6:], k=k)\n",
    "    # device = torch.device('cuda')\n",
    "    # device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # idx_base = 0,512,1024\n",
    "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
    "    \n",
    "    # idx of k-nearest data\n",
    "    idx = idx + idx_base\n",
    "\n",
    "    idx = idx.view(-1)\n",
    "     \n",
    "    _, num_dims, _ = x.size()\n",
    "\n",
    "    x = x.transpose(2, 1).contiguous() # \n",
    "    \n",
    "    # # find k-nearest features in k\n",
    "    feature = x.view(batch_size*num_points, -1)[idx, :] \n",
    "    feature = feature.view(batch_size, num_points, k, num_dims) \n",
    "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
    "    # feature-x: 以x为原点，check相对距离。\n",
    "    feature = torch.cat((feature-x, x), dim=3).permute(0, 3, 1, 2).contiguous()\n",
    "    return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ada354f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoDGCNN_flow2(nn.Module):\n",
    "    def __init__(self, k, emb_dims, dropout):\n",
    "        super(GeoDGCNN_flow2, self).__init__()\n",
    "        # self.args = args\n",
    "        self.k = k\n",
    "        self.emb_dims = emb_dims\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(96)\n",
    "        self.bn4 = nn.BatchNorm2d(96)\n",
    "        self.bn5 = nn.BatchNorm1d(self.emb_dims)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.bn7 = nn.BatchNorm1d(256)\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(32*2, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn1,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "                                   self.bn2,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64*2, 96, kernel_size=1, bias=False),\n",
    "                                   self.bn3,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(96, 96, kernel_size=1, bias=False),\n",
    "                                   self.bn4,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv5 = nn.Sequential(nn.Conv1d(352, self.emb_dims, kernel_size=1, bias=False),\n",
    "                                   self.bn5,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv6 = nn.Sequential(nn.Conv1d(1376, 512, kernel_size=1, bias=False),\n",
    "                                   self.bn6,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.conv7 = nn.Sequential(nn.Conv1d(512, 256, kernel_size=1, bias=False),\n",
    "                                   self.bn7,\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "        self.dp1 = nn.Dropout(p=self.dropout)\n",
    "        self.conv8 = nn.Conv1d(256, 128, kernel_size=1, bias=False)\n",
    "\n",
    "        self.feat_conv1 = GeoSetConv(3, 32)\n",
    "        self.feat_conv2 = GeoSetConv(32, 64)\n",
    "        self.feat_conv3 = GeoSetConv(64, 96)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        geo_graph = ParGraph.construct_graph(x, self.k)\n",
    "        g1 = self.feat_conv1(x, geo_graph)     # B x nb_feat_out x N\n",
    "        g2 = self.feat_conv2(g1, geo_graph)\n",
    "        g3 = self.feat_conv3(g2, geo_graph)\n",
    "        g1 = g1.transpose(1, 2).contiguous() \n",
    "        g2 = g2.transpose(1, 2).contiguous() \n",
    "        g3 = g3.transpose(1, 2).contiguous() \n",
    "        \n",
    "        print('Content of input of get_graph_feature:',g1)\n",
    "        \n",
    "        x = get_graph_feature(g1, k=self.k)  # get graph features   \n",
    "        x = self.conv1(x)                       \n",
    "        x = self.conv2(x)  \n",
    "        \n",
    "        print('Content of x', x)\n",
    "        x2 = x.max(dim=-1, keepdim=False)[0]    \n",
    "\n",
    "        x = get_graph_feature(x2, k=self.k)     \n",
    "        x = self.conv3(x)                       \n",
    "        x = self.conv4(x)                       \n",
    "        x3 = x.max(dim=-1, keepdim=False)[0]    \n",
    "\n",
    "        mid = torch.cat((g1, x2, x3, g2, g3), dim=1)      \n",
    "\n",
    "        x = self.conv5(mid)                       \n",
    "        x = torch.cat((x, mid), dim=1)   \n",
    "        x = self.conv6(x)                       \n",
    "        x = self.conv7(x)                       \n",
    "        x = self.dp1(x)\n",
    "        x = self.conv8(x)                       \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dde22a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlotEncoder(nn.Module):\n",
    "    def __init__(self, num_neighbors=32):\n",
    "        super(FlotEncoder, self).__init__()\n",
    "        n = 32\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.feat_conv1 = SetConv(3, n)\n",
    "        self.feat_conv2 = SetConv(n, 2 * n)\n",
    "        self.feat_conv3 = SetConv(2 * n, 4 * n)\n",
    "\n",
    "    def forward(self, pc):\n",
    "        # pc\n",
    "        graph = Graph.construct_graph(pc, self.num_neighbors)\n",
    "        x = self.feat_conv1(pc, graph)\n",
    "        x = self.feat_conv2(x, graph)\n",
    "        x = self.feat_conv3(x, graph)\n",
    "        x = x.transpose(1, 2).contiguous() # B,C,N\n",
    "        return x, graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261dcf0",
   "metadata": {},
   "source": [
    "## 2.4 DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcf38bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSF_DGCNN(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(RSF_DGCNN, self).__init__()\n",
    "        base_scales = 0.25\n",
    "        truncate_k = 2048\n",
    "        self.hidden_dim = 64\n",
    "        self.context_dim = 64\n",
    "        \n",
    "        self.feature_extractor = GeoDGCNN_flow2(k=32, emb_dims=1024, dropout=0.5)\n",
    "        \n",
    "        self.context_extractor = FlotEncoder()\n",
    "        # self.graph_extractor = FlotGraph()\n",
    "        self.corr_block = CorrBlock2(num_levels=args.corr_levels, base_scale=base_scales,\n",
    "                                    resolution=3, truncate_k=truncate_k)\n",
    "        self.update_block = UpdateBlock(hidden_dim=self.hidden_dim)\n",
    "\n",
    "        self.scale_offset = nn.Parameter(torch.ones(1)/2.0) # torch.ones(1)/10.0\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "        self.epsilon = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, p, num_iters=12):\n",
    "        # feature extraction\n",
    "        [xyz1, xyz2] = p # B x N x 3\n",
    "        fmap1 = self.feature_extractor(p[0])\n",
    "        fmap2 = self.feature_extractor(p[1])\n",
    "        ## modified scale ##\n",
    "        nn_distance = KnnDistance(p[0], 3)\n",
    "        voxel_scale = self.scale_offset * nn_distance\n",
    "\n",
    "        # correlation matrix\n",
    "        transport = ot.sinkhorn(fmap1.transpose(1,-1), fmap2.transpose(1,-1), xyz1, xyz2, \n",
    "            epsilon=torch.exp(self.epsilon) + 0.03, \n",
    "            gamma=self.gamma, #torch.exp(self.gamma), \n",
    "            max_iter=1)\n",
    "        self.corr_block.init_module(fmap1, fmap2, xyz2, transport)\n",
    "        \n",
    "        print('input of flow encoder:',p)\n",
    "        fct1, graph_context = self.context_extractor(p[0]) # Flot Encoder\n",
    "\n",
    "        net, inp = torch.split(fct1, [self.hidden_dim, self.context_dim], dim=1)\n",
    "        net = torch.tanh(net)\n",
    "        inp = torch.relu(inp)\n",
    "\n",
    "        coords1, coords2 = xyz1, xyz1\n",
    "        flow_predictions = []\n",
    "        all_delta_flow = []  \n",
    "\n",
    "        for itr in range(num_iters):\n",
    "            coords2 = coords2.detach()\n",
    "            corr = self.corr_block(coords=coords2, all_delta_flow=all_delta_flow, num_iters=num_iters, scale=voxel_scale)  \n",
    "            flow = coords2 - coords1\n",
    "            net, delta_flow = self.update_block(net, inp, corr, flow, graph_context)\n",
    "            all_delta_flow.append(delta_flow)  \n",
    "            coords2 = coords2 + delta_flow\n",
    "            flow_predictions.append(coords2 - coords1)\n",
    "\n",
    "        return flow_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178676f3",
   "metadata": {},
   "source": [
    "## 2.5 Main training part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "538842e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6fd96a2e93aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRSF_DGCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model = RSF_DGCNN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7a893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
